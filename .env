# ── Active Driver Profiles ──────────────────────────────────
# Comma-separated list of Docker driver profiles to start alongside backend/frontend.
# Available profiles: ur, dobot
# Example:
#   COMPOSE_PROFILES=ur
#
# NOTE: The camera server (camera_server.py) runs natively on Windows — NOT in Docker.
# Start it manually: cd assets/camera_server && uv run python camera_server.py
# The backend connects to it at ws://localhost:8765 (mirrored networking).
COMPOSE_PROFILES=ur

# ── UR Robot Configuration ──────────────────────────────────
ROBOT_IP=192.168.0.10   # UR robot
# ROBOT_IP=192.168.0.101   # PC's own ethernet IP — wrong!
# ROBOT_IP=192.168.163.11    # UR5
UR_TYPE=ur5
# TCP offset: x,y,z,rx,ry,rz in meters and radians
# Set to 0,0,0.055,0,0,0 for 55mm Z offset, or 0,0,0,0,0,0 to disable
ROBOT_TCP_OFFSET=0,0,0,0,0,0

# ── DOBOT Nova 5 ────────────────────────────────────────────
DOBOT_IP=192.168.15.101       # LAN1 port (default)
# Active robot type: ur | dobot  (also update COMPOSE_PROFILES accordingly)
ROBOT_TYPE=ur

# ── COVVI Hand ──────────────────────────────────────────────
HAND_IP=192.168.163.169

# ── ROS 2 ───────────────────────────────────────────────────
ROS_DOMAIN_ID=0

# ── Camera / Vision ─────────────────────────────────────────
# Active camera type: realsense | zivid
CAMERA_TYPE=zivid
# NOTE: zivid_server.py runs natively on Windows — NOT in Docker.
# Start it manually: cd assets/zivid-server && uv run python zivid_server.py
# The backend connects to it at ws://host.docker.internal:8766
ZIVID_SERVER_PORT=8766
CAMERA_BRIDGE_HOST=host.docker.internal
YOLO_MODEL=/app/weights/roboflow_logistics.pt

# ── AI endpoints ────────────────────────────────────────────
# Azure OpenAI — flow generation (POST /api/flows/generate)
AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
AZURE_OPENAI_API_KEY=<your-api-key>
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# Google Gemini — zero-shot vision detection (get_bounding_box_gemini skill)
# Get your key at https://ai.dev/ (Paul from GDM has $25 credits at the hackathon)
GEMINI_API_KEY=AIzaSyDRPlnLMYcYa8H7nKgZYIBE3qTGXiyElaw
# Model to use — gemini-2.0-flash is fast and accurate for object detection
GEMINI_MODEL=gemini-2.0-flash
